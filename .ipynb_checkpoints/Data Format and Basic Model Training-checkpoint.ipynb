{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e5cc5f4",
   "metadata": {},
   "source": [
    "# Basic Model Training\n",
    "\n",
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd9acd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('clean_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984eb657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns\n",
    "df = df.drop(['name'], axis=1)\n",
    "df = df.drop(['released'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9fca30",
   "metadata": {},
   "source": [
    "## Reducing Dimensionality\n",
    "\n",
    "#### The current data has way too many columns, and a bunch with 1.0 correlation. We want to simplify the data to make it easier to train and find more relelvant categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e549f03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# fit and transform the training data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m X_train_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# transform the test data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# import PCA and KNN from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# create an instance of PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# fit and transform the training data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# transform the test data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# create an instance of KNN with 5 neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model to the PCA features\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "# predict on the PCA features\n",
    "y_pred = knn.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12fa668b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCA' object has no attribute 'explained_variance_ratio_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplained_variance_ratio_\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28msum\u001b[39m(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PCA' object has no attribute 'explained_variance_ratio_'"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0fbe3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an MCA object\n",
    "ca = mca.MCA(df_dummies, sparse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea57fbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.70280251e+05],\n",
       "       [ 1.25999009e+08],\n",
       "       [ 8.10740379e+07],\n",
       "       ...,\n",
       "       [-6.09450740e+05],\n",
       "       [-4.96471025e+05],\n",
       "       [-7.19596533e+05]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the coordinates of the rows (observations) in the reduced space\n",
    "ca.fs_r(1) # 1 means using the first principal component\n",
    "\n",
    "# get the coordinates of the columns (variables) in the reduced space\n",
    "ca.fs_c(1) # 1 means using the first principal component\n",
    "\n",
    "# get the eigenvalues of the MCA\n",
    "ca.L # a vector of eigenvalues\n",
    "\n",
    "# project new data into the reduced space\n",
    "df_new_dummies = pd.get_dummies(df_dummies, drop_first=True)\n",
    "ca.fs_r_sup(df_new_dummies, 1) # 1 means using the first principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4171a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coordinates of the original data in the reduced space\n",
    "ca_r = ca.fs_r(1)\n",
    "\n",
    "# get the coordinates of the new data in the reduced space\n",
    "ca_r_sup = ca.fs_r_sup(df_new_dummies, 1)\n",
    "\n",
    "# reshape the ca_r_sup array to have 2 columns\n",
    "ca_r_sup = np.reshape(ca_r_sup, (-1, 2))\n",
    "\n",
    "# combine the two arrays\n",
    "ca_combined = np.concatenate((ca_r, ca_r_sup), axis=0)\n",
    "\n",
    "# convert to a dataframe\n",
    "df_ca = pd.DataFrame(ca_combined, columns=[\"MCA_1\", \"MCA_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ad9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d14c7e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4                     Tomb Raider (2013)\n",
      "4230                            Aseprite\n",
      "9                      BioShock Infinite\n",
      "1835             Total War: WARHAMMER II\n",
      "5198                         Twin Mirror\n",
      "1848               Minecraft: Story Mode\n",
      "4769                           Last Stop\n",
      "8357        Ninja Gaiden 3: Razor's Edge\n",
      "1343    FINAL FANTASY XV WINDOWS EDITION\n",
      "976                            Loop Hero\n",
      "257           The Walking Dead: Season 2\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics.pairwise as pw\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "# get the coordinates of the original data in the reduced space\n",
    "ca_r = ca.fs_r(1)\n",
    "\n",
    "# convert to a dataframe\n",
    "df_ca = pd.DataFrame(ca_r, columns=[\"MCA_1\", \"MCA_2\"])\n",
    "\n",
    "# compute the similarity matrix of items\n",
    "similarity_matrix = pw.cosine_similarity(df_ca)\n",
    "\n",
    "# get similar items for a given item\n",
    "similar_items = similarity_matrix[4]\n",
    "\n",
    "# sort the similar items by similarity score\n",
    "sorted_similar_items = sorted(enumerate(similar_items), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# get the top 10 items\n",
    "top_10_items = sorted_similar_items[:11]\n",
    "\n",
    "\n",
    "\n",
    "# get a list of index labels from top_10_items\n",
    "index_list = [index for index, score in top_10_items]\n",
    "\n",
    "# get the name values for the index list\n",
    "top_10_names = df.loc[index_list, 'name']\n",
    "\n",
    "print(top_10_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6966cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2                The Witcher 3: Wild Hunt\n",
      "3342            Army of Two: The 40th Day\n",
      "3336                            Rock Band\n",
      "4969    Need for Speed: Porsche Unleashed\n",
      "123                            Watch Dogs\n",
      "2054                              FIFA 22\n",
      "5306                       Sakura Dungeon\n",
      "6322           DYNASTY WARRIORS 8 Empires\n",
      "7211          Need for Speed: High Stakes\n",
      "2423                                  SSX\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fb11343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9804, 1992)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7eb0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
